#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾åƒåˆ†ç±»è®­ç»ƒ - LoRAå¾®è°ƒç‰ˆæœ¬
ä½¿ç”¨LoRAå¤§å¹…å‡å°æ¨¡å‹å¤§å°ï¼ˆä»330MBåˆ°~10MBï¼‰
"""

import os
os.environ['HF_HOME'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'
os.environ['TRANSFORMERS_CACHE'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'

import torch
from torch.utils.data import Dataset
from transformers import (
    ViTImageProcessor, 
    ViTForImageClassification,
    TrainingArguments,
    Trainer
)
from peft import LoraConfig, get_peft_model
from PIL import Image
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import json
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(CURRENT_DIR, 'data')
MODEL_DIR = os.path.join(CURRENT_DIR, 'trained_model_lora')
RESULTS_DIR = os.path.join(CURRENT_DIR, 'training_results_lora')

# åˆ›å»ºç›®å½•
os.makedirs(MODEL_DIR, exist_ok=True)
os.makedirs(RESULTS_DIR, exist_ok=True)

print("=" * 70)
print("ğŸ–¼ï¸ å›¾åƒåˆ†ç±»è®­ç»ƒ - LoRAå¾®è°ƒç‰ˆæœ¬")
print("=" * 70)

# å®šä¹‰ç±»åˆ«
CATEGORIES = ['çŒ«', 'ç‹—', 'é¸Ÿ', 'é±¼', 'é©¬']
id2label = {i: label for i, label in enumerate(CATEGORIES)}
label2id = {label: i for i, label in enumerate(CATEGORIES)}

class ImageClassificationDataset(Dataset):
    """å›¾åƒåˆ†ç±»æ•°æ®é›†"""
    
    def __init__(self, data_dir, processor):
        self.data_dir = data_dir
        self.processor = processor
        self.images = []
        self.labels = []
        
        for label_idx, category in enumerate(CATEGORIES):
            category_dir = os.path.join(data_dir, category)
            if not os.path.exists(category_dir):
                continue
            
            for img_name in os.listdir(category_dir):
                if img_name.endswith(('.jpg', '.png', '.jpeg')):
                    img_path = os.path.join(category_dir, img_name)
                    self.images.append(img_path)
                    self.labels.append(label_idx)
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        label = self.labels[idx]
        
        image = Image.open(img_path).convert('RGB')
        encoding = self.processor(images=image, return_tensors="pt")
        pixel_values = encoding['pixel_values'].squeeze()
        
        return {
            'pixel_values': pixel_values,
            'labels': torch.tensor(label, dtype=torch.long)
        }

def compute_metrics(pred):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')
    acc = accuracy_score(labels, preds)
    
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

def plot_training_results(plot_data, save_path):
    """ç»˜åˆ¶è®­ç»ƒç»“æœå›¾"""
    print("\nğŸ“Š ç”Ÿæˆè®­ç»ƒç»“æœå›¾...")
    
    log_history = plot_data['log_history']
    accuracy = plot_data['accuracy']
    precision = plot_data['precision']
    recall = plot_data['recall']
    f1 = plot_data['f1']
    conf_matrix = plot_data['conf_matrix']
    per_class_metrics = plot_data['per_class_metrics']
    
    # æå–è®­ç»ƒæŸå¤±
    train_loss = []
    steps = []
    
    for log in log_history:
        if 'loss' in log and 'eval_loss' not in log:
            train_loss.append(log['loss'])
            steps.append(log.get('step', len(train_loss)))
    
    # åˆ›å»º2x2çš„å­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('å›¾åƒåˆ†ç±» LoRA è®­ç»ƒç»“æœ', fontsize=16, fontweight='bold')
    
    # 1. è®­ç»ƒæŸå¤±æ›²çº¿
    if train_loss:
        axes[0, 0].plot(steps, train_loss, 'b-', linewidth=2, label='è®­ç»ƒæŸå¤±', marker='o', markersize=4)
        axes[0, 0].set_xlabel('è®­ç»ƒæ­¥æ•°', fontsize=11)
        axes[0, 0].set_ylabel('æŸå¤±å€¼', fontsize=11)
        axes[0, 0].set_title('è®­ç»ƒæŸå¤±æ›²çº¿', fontsize=12, fontweight='bold')
        axes[0, 0].legend(fontsize=10)
        axes[0, 0].grid(True, alpha=0.3)
        
        # æ·»åŠ æœ€ç»ˆæŸå¤±å€¼æ ‡æ³¨
        if len(train_loss) > 0:
            final_loss = train_loss[-1]
            final_step = steps[-1]
            axes[0, 0].annotate(f'{final_loss:.4f}', 
                               xy=(final_step, final_loss), 
                               xytext=(10, 10), 
                               textcoords='offset points',
                               bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),
                               fontsize=9)
    
    # 2. æ•´ä½“æŒ‡æ ‡æŸ±çŠ¶å›¾
    metrics_names = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡', 'F1åˆ†æ•°']
    metrics_values = [accuracy, precision, recall, f1]
    colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12']
    
    bars = axes[0, 1].bar(metrics_names, metrics_values, color=colors, alpha=0.7, edgecolor='black')
    axes[0, 1].set_ylabel('åˆ†æ•°', fontsize=11)
    axes[0, 1].set_title('åˆ†ç±»æ€§èƒ½æŒ‡æ ‡', fontsize=12, fontweight='bold')
    axes[0, 1].set_ylim([0, 1])
    axes[0, 1].grid(True, alpha=0.3, axis='y')
    
    # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
    for bar, value in zip(bars, metrics_values):
        height = bar.get_height()
        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,
                       f'{value:.3f}',
                       ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    # 3. æ··æ·†çŸ©é˜µ
    import seaborn as sns
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', 
                xticklabels=CATEGORIES, yticklabels=CATEGORIES,
                ax=axes[1, 0], cbar_kws={'label': 'æ ·æœ¬æ•°'})
    axes[1, 0].set_xlabel('é¢„æµ‹ç±»åˆ«', fontsize=11)
    axes[1, 0].set_ylabel('çœŸå®ç±»åˆ«', fontsize=11)
    axes[1, 0].set_title('æ··æ·†çŸ©é˜µ', fontsize=12, fontweight='bold')
    
    # 4. æ¯ä¸ªç±»åˆ«çš„F1åˆ†æ•°
    x_pos = range(len(CATEGORIES))
    bars = axes[1, 1].bar(x_pos, per_class_metrics['f1'], color='#9b59b6', alpha=0.7, edgecolor='black')
    axes[1, 1].set_xlabel('ç±»åˆ«', fontsize=11)
    axes[1, 1].set_ylabel('F1åˆ†æ•°', fontsize=11)
    axes[1, 1].set_title('å„ç±»åˆ«F1åˆ†æ•°', fontsize=12, fontweight='bold')
    axes[1, 1].set_xticks(x_pos)
    axes[1, 1].set_xticklabels(CATEGORIES, rotation=45, ha='right')
    axes[1, 1].set_ylim([0, 1])
    axes[1, 1].grid(True, alpha=0.3, axis='y')
    
    # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
    for bar, value in zip(bars, per_class_metrics['f1']):
        height = bar.get_height()
        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,
                       f'{value:.2f}',
                       ha='center', va='bottom', fontsize=9)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… è®­ç»ƒç»“æœå›¾å·²ä¿å­˜: {save_path}")
    plt.close()

def main():
    # æ£€æŸ¥æ•°æ®é›†
    train_dir = os.path.join(DATA_DIR, 'train')
    if not os.path.exists(train_dir):
        print(f"\nâŒ é”™è¯¯: æ•°æ®é›†ä¸å­˜åœ¨ï¼")
        print(f"   è¯·ç¡®ä¿æ•°æ®é›†ä½äº: {train_dir}")
        return
    
    print("\nğŸ”§ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
    model_name = "google/vit-base-patch16-224"
    
    processor = ViTImageProcessor.from_pretrained(model_name)
    model = ViTForImageClassification.from_pretrained(
        model_name,
        num_labels=len(CATEGORIES),
        id2label=id2label,
        label2id=label2id,
        ignore_mismatched_sizes=True
    )
    
    print("âœ… åŸºç¡€æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # é…ç½®LoRA
    print("\nğŸ¯ é…ç½®LoRA...")
    lora_config = LoraConfig(
        r=16,  # LoRAç§©
        lora_alpha=32,  # LoRAç¼©æ”¾å› å­
        target_modules=["query", "value"],  # åº”ç”¨LoRAçš„æ¨¡å—
        lora_dropout=0.1,
        bias="none",
    )
    
    # åº”ç”¨LoRA
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()
    
    print("âœ… LoRAé…ç½®å®Œæˆ")
    
    # åˆ›å»ºæ•°æ®é›†
    print("\nğŸ“š å‡†å¤‡æ•°æ®é›†...")
    train_dataset = ImageClassificationDataset(
        os.path.join(DATA_DIR, 'train'),
        processor
    )
    val_dataset = ImageClassificationDataset(
        os.path.join(DATA_DIR, 'val'),
        processor
    )
    
    print(f"âœ… è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"âœ… éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
    
    # è®­ç»ƒå‚æ•°
    training_args = TrainingArguments(
        output_dir=MODEL_DIR,
        num_train_epochs=10,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=8,
        learning_rate=2e-4,  # LoRAé€šå¸¸ç”¨æ›´é«˜çš„å­¦ä¹ ç‡
        warmup_steps=50,
        weight_decay=0.01,
        logging_dir=os.path.join(RESULTS_DIR, 'logs'),
        logging_steps=10,
        evaluation_strategy="epoch",
        save_strategy="no",
        load_best_model_at_end=False,
        push_to_hub=False,
        report_to="none",
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        compute_metrics=compute_metrics,
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("\nğŸš€ å¼€å§‹LoRAå¾®è°ƒ...")
    print("=" * 70)
    
    train_result = trainer.train()
    
    # ä¿å­˜æ¨¡å‹
    print("\nğŸ’¾ ä¿å­˜LoRAæ¨¡å‹...")
    try:
        model.save_pretrained(MODEL_DIR)
        processor.save_pretrained(MODEL_DIR)
        print(f"âœ… LoRAæ¨¡å‹å·²ä¿å­˜åˆ°: {MODEL_DIR}")
        
        # æ£€æŸ¥æ¨¡å‹å¤§å°
        import glob
        model_files = glob.glob(os.path.join(MODEL_DIR, '*.bin')) + glob.glob(os.path.join(MODEL_DIR, '*.safetensors'))
        if model_files:
            total_size = sum(os.path.getsize(f) for f in model_files) / (1024 * 1024)
            print(f"ğŸ“¦ LoRAæ¨¡å‹å¤§å°: {total_size:.2f} MB (åŸæ¨¡å‹: ~330 MB)")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜æ¨¡å‹æ—¶å‡ºé”™: {e}")
    
    # ä¿å­˜è®­ç»ƒä¿¡æ¯
    metrics = train_result.metrics
    trainer.log_metrics("train", metrics)
    trainer.save_metrics("train", metrics)
    
    # æœ€ç»ˆè¯„ä¼°
    print("\nğŸ“Š æœ€ç»ˆè¯„ä¼°...")
    eval_metrics = trainer.evaluate()
    
    # æ‰‹åŠ¨è®¡ç®—è¯¦ç»†æŒ‡æ ‡
    print("\nï¿½ æ‰‹åŠ¨è®¡ç®—åˆ†ç±»æŒ‡æ ‡...")
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for batch in trainer.get_eval_dataloader():
            pixel_values = batch['pixel_values'].to(model.device)
            labels = batch['labels'].to(model.device)
            
            outputs = model(pixel_values=pixel_values)
            preds = outputs.logits.argmax(dim=-1)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    # è®¡ç®—æŒ‡æ ‡
    from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
    import seaborn as sns
    
    accuracy = accuracy_score(all_labels, all_preds)
    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')
    conf_matrix = confusion_matrix(all_labels, all_preds)
    
    # æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
    per_class_precision, per_class_recall, per_class_f1, _ = precision_recall_fscore_support(
        all_labels, all_preds, average=None
    )
    
    print(f"   å‡†ç¡®ç‡: {accuracy:.4f}")
    print(f"   ç²¾ç¡®ç‡: {precision:.4f}")
    print(f"   å¬å›ç‡: {recall:.4f}")
    print(f"   F1åˆ†æ•°: {f1:.4f}")
    
    # æ›´æ–°eval_metrics
    eval_metrics['eval_accuracy'] = accuracy
    eval_metrics['eval_precision'] = precision
    eval_metrics['eval_recall'] = recall
    eval_metrics['eval_f1'] = f1
    
    trainer.log_metrics("eval", eval_metrics)
    trainer.save_metrics("eval", eval_metrics)
    
    # ç»˜åˆ¶è®­ç»ƒç»“æœï¼ˆåŒ…å«æ‰‹åŠ¨è®¡ç®—çš„æŒ‡æ ‡ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    plot_path = os.path.join(RESULTS_DIR, f'training_results_{timestamp}.png')
    
    # å‡†å¤‡ç»˜å›¾æ•°æ®
    plot_data = {
        'log_history': trainer.state.log_history,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'conf_matrix': conf_matrix,
        'per_class_metrics': {
            'precision': per_class_precision,
            'recall': per_class_recall,
            'f1': per_class_f1
        }
    }
    
    plot_training_results(plot_data, save_path=plot_path)
    
    # ä¿å­˜è®­ç»ƒæ‘˜è¦
    summary = {
        'è®­ç»ƒæ—¶é—´': timestamp,
        'æ¨¡å‹': model_name,
        'å¾®è°ƒæ–¹æ³•': 'LoRA',
        'LoRAé…ç½®': {
            'r': lora_config.r,
            'lora_alpha': lora_config.lora_alpha,
            'target_modules': lora_config.target_modules,
        },
        'ç±»åˆ«æ•°': len(CATEGORIES),
        'ç±»åˆ«': CATEGORIES,
        'è®­ç»ƒæ ·æœ¬æ•°': len(train_dataset),
        'éªŒè¯æ ·æœ¬æ•°': len(val_dataset),
        'è®­ç»ƒè½®æ•°': training_args.num_train_epochs,
        'æœ€ç»ˆæŒ‡æ ‡': {
            'å‡†ç¡®ç‡': f"{eval_metrics.get('eval_accuracy', 0):.4f}",
            'F1åˆ†æ•°': f"{eval_metrics.get('eval_f1', 0):.4f}",
            'ç²¾ç¡®ç‡': f"{eval_metrics.get('eval_precision', 0):.4f}",
            'å¬å›ç‡': f"{eval_metrics.get('eval_recall', 0):.4f}",
        }
    }
    
    summary_path = os.path.join(RESULTS_DIR, f'training_summary_{timestamp}.json')
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 70)
    print("âœ… LoRAå¾®è°ƒå®Œæˆï¼")
    print("=" * 70)
    print(f"\nğŸ“ æ¨¡å‹ä¿å­˜ä½ç½®: {MODEL_DIR}")
    print(f"ğŸ“Š è®­ç»ƒç»“æœå›¾: {plot_path}")
    print(f"ğŸ“„ è®­ç»ƒæ‘˜è¦: {summary_path}")
    print(f"\nğŸ¯ æœ€ç»ˆå‡†ç¡®ç‡: {accuracy:.2%}")
    print(f"ğŸ¯ æœ€ç»ˆF1åˆ†æ•°: {f1:.4f}")
    print(f"\nğŸ’¡ LoRAä¼˜åŠ¿: æ¨¡å‹å¤§å°ä»~330MBå‡å°‘åˆ°~10MBï¼")

if __name__ == '__main__':
    main()
