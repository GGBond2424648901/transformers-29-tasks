#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å§¿æ€ä¼°è®¡å®æ—¶æ£€æµ‹ - æ”¯æŒæ‘„åƒå¤´å’Œè§†é¢‘æ–‡ä»¶ ğŸ¥
"""

import os
os.environ['HF_HOME'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'
os.environ['TRANSFORMERS_CACHE'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'

import cv2
import numpy as np
from PIL import Image
import time

# ä¿å­˜åŸå§‹çš„cv2.imshowï¼Œé¿å…è¢«ultralytics patch
_original_imshow = cv2.imshow

# ä½¿ç”¨YOLOè¿›è¡Œäººä½“æ£€æµ‹
try:
    from ultralytics import YOLO
    yolo_model = YOLO('yolov8n.pt')
    USE_YOLO = True
    print("âœ… YOLOæ¨¡å‹åŠ è½½æˆåŠŸ")
    # æ¢å¤åŸå§‹çš„imshowå‡½æ•°
    cv2.imshow = _original_imshow
except Exception as e:
    USE_YOLO = False
    yolo_model = None
    print(f"âš ï¸ YOLOåŠ è½½å¤±è´¥: {e}")

# ä½¿ç”¨OpenPoseè¿›è¡Œå§¿æ€ä¼°è®¡
try:
    from controlnet_aux import OpenposeDetector
    pose_detector = OpenposeDetector.from_pretrained("lllyasviel/ControlNet")
    USE_OPENPOSE = True
    print("âœ… OpenPoseæ¨¡å‹åŠ è½½æˆåŠŸ")
except Exception as e:
    USE_OPENPOSE = False
    pose_detector = None
    print(f"âš ï¸ OpenPoseåŠ è½½å¤±è´¥: {e}")

print("\n" + "=" * 70)
print("ğŸ¥ å§¿æ€ä¼°è®¡å®æ—¶æ£€æµ‹ç³»ç»Ÿ")
print("=" * 70)
print("\né€‰æ‹©æ£€æµ‹æ¨¡å¼ï¼š")
print("1. æ‘„åƒå¤´å®æ—¶æ£€æµ‹")
print("2. è§†é¢‘æ–‡ä»¶æ£€æµ‹")
print("3. é€€å‡º")

def detect_pose_in_frame(frame):
    """å¯¹å•å¸§å›¾åƒè¿›è¡Œå§¿æ€æ£€æµ‹"""
    # è½¬æ¢ä¸ºPIL Image
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(frame_rgb)
    
    # YOLOæ£€æµ‹äººæ•°
    num_people = 0
    if USE_YOLO and yolo_model:
        try:
            results = yolo_model(pil_image, verbose=False)
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    if int(box.cls[0]) == 0:  # person
                        num_people += 1
        except:
            pass
    
    # OpenPoseæ£€æµ‹éª¨éª¼
    pose_image = None
    if USE_OPENPOSE and pose_detector:
        try:
            pose_image = pose_detector(pil_image, detect_resolution=384, image_resolution=384)
            # è½¬æ¢å›OpenCVæ ¼å¼
            pose_array = np.array(pose_image)
            pose_bgr = cv2.cvtColor(pose_array, cv2.COLOR_RGB2BGR)
        except Exception as e:
            print(f"å§¿æ€æ£€æµ‹å¤±è´¥: {e}")
            pose_bgr = frame.copy()
    else:
        pose_bgr = frame.copy()
    
    return pose_bgr, num_people

def camera_detection():
    """æ‘„åƒå¤´å®æ—¶æ£€æµ‹"""
    print("\nğŸ¥ å¯åŠ¨æ‘„åƒå¤´...")
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return
    
    print("âœ… æ‘„åƒå¤´å·²å¯åŠ¨")
    print("\næ“ä½œè¯´æ˜ï¼š")
    print("  - æŒ‰ 'q' é€€å‡º")
    print("  - æŒ‰ 's' æˆªå›¾ä¿å­˜")
    print("  - æŒ‰ 'p' æš‚åœ/ç»§ç»­")
    
    paused = False
    frame_count = 0
    fps_time = time.time()
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                break
            
            # æ£€æµ‹å§¿æ€
            pose_frame, num_people = detect_pose_in_frame(frame)
            
            # è®¡ç®—FPS
            frame_count += 1
            if frame_count % 10 == 0:
                fps = 10 / (time.time() - fps_time)
                fps_time = time.time()
            else:
                fps = 0
            
            # æ·»åŠ ä¿¡æ¯æ–‡å­—
            if fps > 0:
                cv2.putText(pose_frame, f'FPS: {fps:.1f}', (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(pose_frame, f'People: {num_people}', (10, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(pose_frame, 'Press Q to quit', (10, pose_frame.shape[0] - 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # æ˜¾ç¤ºç”»é¢
            cv2.imshow('Pose Detection - Camera', pose_frame)
        
        # æŒ‰é”®å¤„ç†
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('s'):
            filename = f'pose_capture_{int(time.time())}.jpg'
            cv2.imwrite(filename, pose_frame)
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {filename}")
        elif key == ord('p'):
            paused = not paused
            print("â¸ï¸ æš‚åœ" if paused else "â–¶ï¸ ç»§ç»­")
    
    cap.release()
    cv2.destroyAllWindows()
    print("\nâœ… æ‘„åƒå¤´æ£€æµ‹ç»“æŸ")

def video_detection():
    """è§†é¢‘æ–‡ä»¶æ£€æµ‹"""
    print("\nğŸ“¹ è¯·è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼š")
    video_path = input("> ").strip().strip('"')
    
    if not os.path.exists(video_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
        return
    
    # è·å–è§†é¢‘ä¿¡æ¯
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"\nâœ… è§†é¢‘ä¿¡æ¯:")
    print(f"  - åˆ†è¾¨ç‡: {width}x{height}")
    print(f"  - å¸§ç‡: {fps} FPS")
    print(f"  - æ€»å¸§æ•°: {total_frames}")
    print(f"  - æ—¶é•¿: {total_frames/fps:.1f} ç§’")
    
    print("\næ˜¯å¦ä¿å­˜å¤„ç†åçš„è§†é¢‘ï¼Ÿ(y/n)")
    save_video = input("> ").strip().lower() == 'y'
    
    out = None
    if save_video:
        output_path = f'pose_output_{int(time.time())}.mp4'
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        print(f"ğŸ“¹ å°†ä¿å­˜åˆ°: {output_path}")
    
    print("\næ“ä½œè¯´æ˜ï¼š")
    print("  - æŒ‰ 'q' é€€å‡º")
    print("  - æŒ‰ 'p' æš‚åœ/ç»§ç»­")
    print("  - æŒ‰ 'â†’' å¿«è¿›10å¸§")
    print("  - æŒ‰ 'â†' åé€€10å¸§")
    
    paused = False
    frame_idx = 0
    
    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                print("\nâœ… è§†é¢‘å¤„ç†å®Œæˆ")
                break
            
            frame_idx += 1
            
            # æ£€æµ‹å§¿æ€
            pose_frame, num_people = detect_pose_in_frame(frame)
            
            # æ·»åŠ ä¿¡æ¯æ–‡å­—
            progress = (frame_idx / total_frames) * 100
            cv2.putText(pose_frame, f'Frame: {frame_idx}/{total_frames} ({progress:.1f}%)', 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(pose_frame, f'People: {num_people}', (10, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # ä¿å­˜è§†é¢‘
            if out is not None:
                out.write(pose_frame)
            
            # æ˜¾ç¤ºç”»é¢
            cv2.imshow('Pose Detection - Video', pose_frame)
        
        # æŒ‰é”®å¤„ç†
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('p'):
            paused = not paused
            print("â¸ï¸ æš‚åœ" if paused else "â–¶ï¸ ç»§ç»­")
        elif key == 83:  # å³ç®­å¤´
            frame_idx = min(frame_idx + 10, total_frames)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            print(f"â© å¿«è¿›åˆ°ç¬¬ {frame_idx} å¸§")
        elif key == 81:  # å·¦ç®­å¤´
            frame_idx = max(frame_idx - 10, 0)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            print(f"âª åé€€åˆ°ç¬¬ {frame_idx} å¸§")
    
    cap.release()
    if out is not None:
        out.release()
        print(f"\nâœ… è§†é¢‘å·²ä¿å­˜: {output_path}")
    cv2.destroyAllWindows()

def main():
    """ä¸»å‡½æ•°"""
    while True:
        choice = input("\nè¯·é€‰æ‹© (1/2/3): ").strip()
        
        if choice == '1':
            camera_detection()
        elif choice == '2':
            video_detection()
        elif choice == '3':
            print("\nğŸ‘‹ å†è§ï¼")
            break
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")

if __name__ == '__main__':
    if not USE_YOLO and not USE_OPENPOSE:
        print("\nâŒ é”™è¯¯ï¼šYOLOå’ŒOpenPoseéƒ½æœªåŠ è½½æˆåŠŸ")
        print("è¯·ç¡®ä¿å·²å®‰è£…ï¼š")
        print("  pip install ultralytics")
        print("  pip install controlnet-aux")
    else:
        main()
