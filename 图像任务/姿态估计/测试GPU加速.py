#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUåŠ é€Ÿæ€§èƒ½æµ‹è¯•
"""

import os
os.environ['HF_HOME'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'
os.environ['TRANSFORMERS_CACHE'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'

import torch
import time
import cv2
import numpy as np
from PIL import Image

print("=" * 70)
print("ğŸš€ GPUåŠ é€Ÿæ€§èƒ½æµ‹è¯•")
print("=" * 70)

# 1. æ£€æŸ¥PyTorch CUDAæ”¯æŒ
print("\nã€1ã€‘PyTorch CUDAæ£€æµ‹")
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
    print(f"å½“å‰GPU: {torch.cuda.current_device()}")
    print(f"GPUåç§°: {torch.cuda.get_device_name(0)}")
    print(f"GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
else:
    print("âŒ CUDAä¸å¯ç”¨ï¼è¯·å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch")
    print("   å®‰è£…å‘½ä»¤: pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118")

# 2. æµ‹è¯•YOLO GPUåŠ é€Ÿ
print("\nã€2ã€‘YOLO GPUåŠ é€Ÿæµ‹è¯•")
try:
    from ultralytics import YOLO
    
    # åŠ è½½æ¨¡å‹
    print("åŠ è½½YOLOæ¨¡å‹...")
    model = YOLO('yolov8n.pt')
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_image = np.random.randint(0, 255, (640, 480, 3), dtype=np.uint8)
    test_pil = Image.fromarray(test_image)
    
    # CPUæµ‹è¯•
    print("\næµ‹è¯•CPUæ¨¡å¼...")
    model.to('cpu')
    start = time.time()
    for i in range(10):
        results = model(test_pil, verbose=False, device='cpu')
    cpu_time = (time.time() - start) / 10
    print(f"CPUå¹³å‡è€—æ—¶: {cpu_time*1000:.2f} ms/å¸§")
    print(f"CPU FPS: {1/cpu_time:.2f}")
    
    # GPUæµ‹è¯•
    if torch.cuda.is_available():
        print("\næµ‹è¯•GPUæ¨¡å¼...")
        model.to('cuda')
        
        # é¢„çƒ­GPU
        for i in range(3):
            results = model(test_pil, verbose=False, device='cuda')
        
        start = time.time()
        for i in range(10):
            results = model(test_pil, verbose=False, device='cuda')
        gpu_time = (time.time() - start) / 10
        print(f"GPUå¹³å‡è€—æ—¶: {gpu_time*1000:.2f} ms/å¸§")
        print(f"GPU FPS: {1/gpu_time:.2f}")
        print(f"åŠ é€Ÿæ¯”: {cpu_time/gpu_time:.2f}x")
        
        if gpu_time >= cpu_time:
            print("âš ï¸ è­¦å‘Š: GPUé€Ÿåº¦æ²¡æœ‰æ¯”CPUå¿«ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜ï¼")
    
    print("âœ… YOLOæµ‹è¯•å®Œæˆ")
    
except Exception as e:
    print(f"âŒ YOLOæµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# 3. æµ‹è¯•OpenPose GPUåŠ é€Ÿ
print("\nã€3ã€‘OpenPose GPUåŠ é€Ÿæµ‹è¯•")
try:
    from controlnet_aux import OpenposeDetector
    
    print("åŠ è½½OpenPoseæ¨¡å‹...")
    detector = OpenposeDetector.from_pretrained("lllyasviel/ControlNet")
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰GPUæ”¯æŒ
    if hasattr(detector, 'model_pose'):
        print(f"OpenPoseæ¨¡å‹ç±»å‹: {type(detector.model_pose)}")
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        test_pil = Image.fromarray(test_image)
        
        # CPUæµ‹è¯•
        print("\næµ‹è¯•CPUæ¨¡å¼...")
        if hasattr(detector.model_pose, 'to'):
            detector.model_pose = detector.model_pose.to('cpu')
        
        start = time.time()
        for i in range(5):
            result = detector(test_pil, detect_resolution=192, image_resolution=192, hand_and_face=False)
        cpu_time = (time.time() - start) / 5
        print(f"CPUå¹³å‡è€—æ—¶: {cpu_time*1000:.2f} ms/å¸§")
        print(f"CPU FPS: {1/cpu_time:.2f}")
        
        # GPUæµ‹è¯•
        if torch.cuda.is_available():
            print("\næµ‹è¯•GPUæ¨¡å¼...")
            if hasattr(detector.model_pose, 'to'):
                detector.model_pose = detector.model_pose.to('cuda')
                
                # é¢„çƒ­GPU
                for i in range(2):
                    result = detector(test_pil, detect_resolution=192, image_resolution=192, hand_and_face=False)
                
                start = time.time()
                for i in range(5):
                    result = detector(test_pil, detect_resolution=192, image_resolution=192, hand_and_face=False)
                gpu_time = (time.time() - start) / 5
                print(f"GPUå¹³å‡è€—æ—¶: {gpu_time*1000:.2f} ms/å¸§")
                print(f"GPU FPS: {1/gpu_time:.2f}")
                print(f"åŠ é€Ÿæ¯”: {cpu_time/gpu_time:.2f}x")
                
                if gpu_time >= cpu_time:
                    print("âš ï¸ è­¦å‘Š: GPUé€Ÿåº¦æ²¡æœ‰æ¯”CPUå¿«ï¼ŒOpenPoseå¯èƒ½æœªä½¿ç”¨GPUï¼")
            else:
                print("âš ï¸ OpenPoseæ¨¡å‹ä¸æ”¯æŒ.to()æ–¹æ³•ï¼Œå¯èƒ½æ— æ³•ä½¿ç”¨GPU")
    else:
        print("âš ï¸ æ— æ³•è®¿é—®OpenPoseå†…éƒ¨æ¨¡å‹")
    
    print("âœ… OpenPoseæµ‹è¯•å®Œæˆ")
    
except Exception as e:
    print(f"âŒ OpenPoseæµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# 4. ç»¼åˆæ€§èƒ½è¯„ä¼°
print("\nã€4ã€‘ç»¼åˆæ€§èƒ½è¯„ä¼°")
print("=" * 70)

if torch.cuda.is_available():
    print("âœ… GPUåŠ é€Ÿå¯ç”¨")
    print("\næ¨èé…ç½®:")
    print("  - detect_resolution: 192 (å¹³è¡¡é€Ÿåº¦å’Œç²¾åº¦)")
    print("  - hand_and_face: False (æé«˜é€Ÿåº¦)")
    print("  - JPEGè´¨é‡: 70 (å‡å°‘ä¼ è¾“æ—¶é—´)")
    print("  - è·³å¸§: 1 (ä¸è·³å¸§ï¼Œå®æ—¶æ€§æœ€å¥½)")
    print("\né¢„æœŸæ€§èƒ½:")
    print("  - YOLO: 5-10ms/å¸§")
    print("  - OpenPose: 30-50ms/å¸§")
    print("  - æ€»å»¶è¿Ÿ: 40-70ms/å¸§")
    print("  - FPS: 15-25")
else:
    print("âŒ GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
    print("\né¢„æœŸæ€§èƒ½:")
    print("  - YOLO: 50-100ms/å¸§")
    print("  - OpenPose: 200-400ms/å¸§")
    print("  - æ€»å»¶è¿Ÿ: 300-500ms/å¸§")
    print("  - FPS: 2-3")

print("\n" + "=" * 70)
print("æµ‹è¯•å®Œæˆï¼")
print("=" * 70)
