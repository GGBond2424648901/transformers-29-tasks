#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°é—»åˆ†ç±»å™¨è®­ç»ƒç¤ºä¾‹
ä½¿ç”¨ BERT è®­ç»ƒä¸€ä¸ª6åˆ†ç±»çš„æ–°é—»åˆ†ç±»å™¨
"""

import os
os.environ['HF_HOME'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'
os.environ['TRANSFORMERS_CACHE'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'

import pandas as pd
import numpy as np
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    DataCollatorWithPadding
)
from datasets import Dataset
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report
import torch

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(CURRENT_DIR, 'data')
OUTPUT_DIR = os.path.join(CURRENT_DIR, 'output', 'news_classifier')

# ç±»åˆ«æ ‡ç­¾
LABELS = {
    0: "ç§‘æŠ€",
    1: "ä½“è‚²", 
    2: "å¨±ä¹",
    3: "è´¢ç»",
    4: "ç¤¾ä¼š",
    5: "æ”¿æ²»"
}

print("=" * 70)
print("ğŸ“° æ–°é—»åˆ†ç±»å™¨è®­ç»ƒ")
print("=" * 70)

# 1. åŠ è½½æ•°æ®
print("\nğŸ“Š æ­¥éª¤ 1/6: åŠ è½½æ•°æ®...")
train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))
test_df = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))

# åˆ é™¤åŒ…å«NaNçš„è¡Œ
train_df = train_df.dropna()
test_df = test_df.dropna()

# ç¡®ä¿æ ‡ç­¾æ˜¯æ•´æ•°ç±»å‹
train_df['label'] = train_df['label'].astype(int)
test_df['label'] = test_df['label'].astype(int)

print(f"   è®­ç»ƒé›†: {len(train_df)} æ¡")
print(f"   æµ‹è¯•é›†: {len(test_df)} æ¡")
print(f"   ç±»åˆ«æ•°: {len(LABELS)}")
print("\n   ç±»åˆ«åˆ†å¸ƒ:")
for label_id, label_name in LABELS.items():
    count = len(train_df[train_df['label'] == label_id])
    print(f"   {label_id}. {label_name}: {count} æ¡")

# è½¬æ¢ä¸º Dataset æ ¼å¼
train_dataset = Dataset.from_pandas(train_df)
test_dataset = Dataset.from_pandas(test_df)

# 2. åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
print("\nğŸ¤– æ­¥éª¤ 2/6: åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨...")
model_name = "bert-base-chinese"
print(f"   æ¨¡å‹: {model_name}")

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=len(LABELS)
)

# æ£€æµ‹ GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"   è®¾å¤‡: {device}")

# 3. æ•°æ®é¢„å¤„ç†
print("\nğŸ”§ æ­¥éª¤ 3/6: æ•°æ®é¢„å¤„ç†...")

def preprocess_function(examples):
    """å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯"""
    return tokenizer(
        examples["text"],
        truncation=True,
        max_length=128,
        padding=False  # ä½¿ç”¨ DataCollator åŠ¨æ€padding
    )

# å¯¹æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†
tokenized_train = train_dataset.map(preprocess_function, batched=True)
tokenized_test = test_dataset.map(preprocess_function, batched=True)

print("   âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")

# 4. å®šä¹‰è¯„ä¼°å‡½æ•°
def compute_metrics(eval_pred):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = accuracy_score(labels, predictions)
    
    # è®¡ç®—ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, predictions, average='weighted'
    )
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }

# 5. è®­ç»ƒé…ç½®
print("\nâš™ï¸  æ­¥éª¤ 4/6: é…ç½®è®­ç»ƒå‚æ•°...")

training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    evaluation_strategy="epoch",
    save_strategy="no",  # ä¸ä¿å­˜ä¸­é—´checkpoint
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=5,
    weight_decay=0.01,
    logging_steps=10,
    report_to="none"  # ä¸ä½¿ç”¨wandbç­‰
)

print(f"   å­¦ä¹ ç‡: {training_args.learning_rate}")
print(f"   æ‰¹æ¬¡å¤§å°: {training_args.per_device_train_batch_size}")
print(f"   è®­ç»ƒè½®æ•°: {training_args.num_train_epochs}")
print(f"   è¾“å‡ºç›®å½•: {OUTPUT_DIR}")

# æ•°æ®æ•´ç†å™¨
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# 6. åˆ›å»º Trainer
print("\nğŸ¯ æ­¥éª¤ 5/6: åˆ›å»º Trainer...")

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_test,
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics
)

# 7. å¼€å§‹è®­ç»ƒ
print("\nğŸš€ æ­¥éª¤ 6/6: å¼€å§‹è®­ç»ƒ...")
print("=" * 70)

train_result = trainer.train()

print("\n" + "=" * 70)
print("âœ… è®­ç»ƒå®Œæˆï¼")
print("=" * 70)

# 8. è¯„ä¼°æ¨¡å‹
print("\nğŸ“Š æœ€ç»ˆè¯„ä¼°...")
eval_results = trainer.evaluate()

print("\nè¯„ä¼°ç»“æœ:")
print(f"   å‡†ç¡®ç‡: {eval_results['eval_accuracy']:.4f}")
print(f"   ç²¾ç¡®ç‡: {eval_results['eval_precision']:.4f}")
print(f"   å¬å›ç‡: {eval_results['eval_recall']:.4f}")
print(f"   F1åˆ†æ•°: {eval_results['eval_f1']:.4f}")

# 9. è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
print("\nğŸ“ˆ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
predictions = trainer.predict(tokenized_test)
preds = np.argmax(predictions.predictions, axis=1)

report = classification_report(
    test_df['label'],
    preds,
    target_names=[LABELS[i] for i in range(len(LABELS))],
    digits=4
)
print(report)

# 10. ä¿å­˜æ¨¡å‹
print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
trainer.save_model(OUTPUT_DIR)
tokenizer.save_pretrained(OUTPUT_DIR)

# ä¿å­˜æ ‡ç­¾æ˜ å°„
import json
label_map_path = os.path.join(OUTPUT_DIR, 'label_map.json')
with open(label_map_path, 'w', encoding='utf-8') as f:
    json.dump(LABELS, f, ensure_ascii=False, indent=2)

print(f"   æ¨¡å‹å·²ä¿å­˜åˆ°: {OUTPUT_DIR}")
print(f"   æ ‡ç­¾æ˜ å°„å·²ä¿å­˜åˆ°: {label_map_path}")

# 11. æµ‹è¯•æ¨ç†
print("\nğŸ§ª æµ‹è¯•æ¨ç†...")
print("=" * 70)

# åŠ è½½ä¿å­˜çš„æ¨¡å‹
from transformers import pipeline

classifier = pipeline(
    "text-classification",
    model=OUTPUT_DIR,
    tokenizer=OUTPUT_DIR,
    device=0 if device == "cuda" else -1
)

# æµ‹è¯•æ ·æœ¬
test_texts = [
    "è‹¹æœå…¬å¸å‘å¸ƒæ–°æ¬¾MacBook Proï¼Œæ­è½½M3èŠ¯ç‰‡",
    "ä¸­å›½å¥³ç¯®æˆ˜èƒœç¾å›½é˜Ÿï¼Œå¤ºå¾—ä¸–ç•Œæ¯å† å†›",
    "å‘¨æ°ä¼¦æ–°ä¸“è¾‘å‘å¸ƒï¼Œé¦–æ—¥é”€é‡ç ´ç™¾ä¸‡",
    "Aè‚¡å¤§æ¶¨ï¼Œæ²ªæŒ‡çªç ´3500ç‚¹",
    "åŒ—äº¬ä»Šæ—¥æœ‰é›¨ï¼Œæ°”æ¸©ä¸‹é™",
    "æ•™è‚²éƒ¨å‘å¸ƒæ–°è§„ï¼Œè§„èŒƒæ ¡å¤–åŸ¹è®­"
]

print("\næµ‹è¯•æ ·æœ¬é¢„æµ‹:")
for text in test_texts:
    result = classifier(text)[0]
    label_id = int(result['label'].split('_')[-1])
    label_name = LABELS[label_id]
    score = result['score']
    print(f"\næ–‡æœ¬: {text}")
    print(f"é¢„æµ‹: {label_name} (ç½®ä¿¡åº¦: {score:.4f})")

print("\n" + "=" * 70)
print("âœ¨ å…¨éƒ¨å®Œæˆï¼")
print("=" * 70)
print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
print(f"   1. æ¨¡å‹ä¿å­˜åœ¨: {OUTPUT_DIR}")
print("   2. å¯ä»¥ä½¿ç”¨ pipeline åŠ è½½æ¨¡å‹è¿›è¡Œæ¨ç†")
print("   3. æŸ¥çœ‹ label_map.json äº†è§£ç±»åˆ«æ˜ å°„")
print("\nğŸ“ ä¸‹ä¸€æ­¥:")
print("   - è¿è¡Œ æ–°é—»åˆ†ç±»æµ‹è¯•.py æµ‹è¯•æ¨¡å‹")
print("   - æˆ–åˆ›å»º Web æœåŠ¡éƒ¨ç½²æ¨¡å‹")
