# ğŸ­ æ©ç è¯å¡«å……ï¼ˆFill-Mask / Masked Language Modelingï¼‰

## ğŸ“– ä»»åŠ¡ç®€ä»‹

æ©ç è¯å¡«å……æ˜¯ä¸€ç§é¢„è®­ç»ƒä»»åŠ¡ï¼Œé€šè¿‡é¢„æµ‹è¢«æ©ç ï¼ˆmaskï¼‰çš„è¯æ¥å­¦ä¹ è¯­è¨€è¡¨ç¤ºã€‚BERT ç­‰æ¨¡å‹å°±æ˜¯é€šè¿‡è¿™ç§æ–¹å¼è¿›è¡Œé¢„è®­ç»ƒçš„ã€‚è¿™ä¸ªä»»åŠ¡å¯ä»¥ç”¨äºè¯è¯­é¢„æµ‹ã€æ–‡æœ¬çº é”™ã€æ™ºèƒ½è¾“å…¥æ³•ç­‰åœºæ™¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

- **ğŸ“ æ™ºèƒ½è¾“å…¥æ³•**: è¯è¯­è”æƒ³ã€è‡ªåŠ¨è¡¥å…¨
- **ğŸ”§ æ–‡æœ¬çº é”™**: æ‹¼å†™æ£€æŸ¥ã€è¯­æ³•çº æ­£
- **ğŸ“š è¯­è¨€å­¦ä¹ **: å¡«ç©ºç»ƒä¹ ã€è¯æ±‡æµ‹è¯•
- **ğŸ¤– å¯¹è¯ç³»ç»Ÿ**: å¥å­è¡¥å…¨ã€æ„å›¾ç†è§£
- **ğŸ“Š æ•°æ®å¢å¼º**: ç”Ÿæˆç›¸ä¼¼å¥å­ã€åŒä¹‰è¯æ›¿æ¢

## ğŸ“ æ–‡ä»¶è¯´æ˜

- `æ©ç è¯å¡«å……ç¤ºä¾‹.py` - Pipeline æ¨ç†ç¤ºä¾‹
- `README.md` - æœ¬æ–‡ä»¶

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install transformers torch
```

### 2. è¿è¡Œç¤ºä¾‹

```bash
python æ©ç è¯å¡«å……ç¤ºä¾‹.py
```

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€å¡«å……

```python
from transformers import pipeline

# åˆ›å»ºå¡«å……å™¨ï¼ˆä¸­æ–‡ï¼‰
unmasker = pipeline(
    "fill-mask",
    model="bert-base-chinese"
)

# å¡«å……æ©ç è¯
text = "ä»Šå¤©å¤©æ°”çœŸ[MASK]ï¼"
results = unmasker(text)

# æŸ¥çœ‹ç»“æœ
for result in results:
    print(f"{result['token_str']}: {result['score']:.2%}")
    print(f"å®Œæ•´å¥å­: {result['sequence']}")
```

### è‹±æ–‡å¡«å……

```python
# è‹±æ–‡æ¨¡å‹
unmasker_en = pipeline(
    "fill-mask",
    model="bert-base-uncased"
)

text = "The weather is [MASK] today."
results = unmasker_en(text)

for result in results:
    print(f"{result['token_str']}: {result['score']:.2%}")
```

### æ§åˆ¶è¾“å‡ºæ•°é‡

```python
# è¿”å›å‰ 10 ä¸ªé¢„æµ‹
results = unmasker(text, top_k=10)

# åªè¿”å›æœ€ä½³é¢„æµ‹
best = unmasker(text, top_k=1)[0]
print(f"æœ€ä½³é¢„æµ‹: {best['token_str']}")
```

## ğŸ¨ æ¨èæ¨¡å‹

### ä¸­æ–‡æ¨¡å‹

| æ¨¡å‹ | å¤§å° | ç‰¹ç‚¹ |
|------|------|------|
| bert-base-chinese | ä¸­ | é€šç”¨ä¸­æ–‡ BERT |
| hfl/chinese-roberta-wwm-ext | ä¸­ | å…¨è¯æ©ç ï¼Œæ•ˆæœæ›´å¥½ |
| hfl/chinese-bert-wwm-ext | ä¸­ | å…¨è¯æ©ç  BERT |
| uer/chinese_roberta_L-12_H-768 | ä¸­ | ä¸­æ–‡ RoBERTa |

### è‹±æ–‡æ¨¡å‹

| æ¨¡å‹ | å¤§å° | ç‰¹ç‚¹ |
|------|------|------|
| bert-base-uncased | ä¸­ | é€šç”¨è‹±æ–‡ BERT |
| roberta-base | ä¸­ | è‹±æ–‡ RoBERTaï¼Œæ•ˆæœæ›´å¥½ |
| albert-base-v2 | å° | è½»é‡çº§æ¨¡å‹ |
| distilbert-base-uncased | å° | è’¸é¦ç‰ˆ BERTï¼Œé€Ÿåº¦å¿« |

## ğŸ’¡ ä½¿ç”¨æŠ€å·§

### 1. ä¸åŒæ¨¡å‹çš„æ©ç æ ‡è®°

```python
# BERT: [MASK]
text_bert = "ä»Šå¤©å¤©æ°”çœŸ[MASK]ï¼"

# RoBERTa: <mask>
text_roberta = "ä»Šå¤©å¤©æ°”çœŸ<mask>ï¼"

# ä½¿ç”¨å¯¹åº”çš„æ¨¡å‹
unmasker_bert = pipeline("fill-mask", model="bert-base-chinese")
unmasker_roberta = pipeline("fill-mask", model="hfl/chinese-roberta-wwm-ext")
```

### 2. å¤šä¸ªæ©ç è¯

```python
# æ³¨æ„ï¼šä¸€æ¬¡åªèƒ½å¡«å……ä¸€ä¸ªæ©ç 
# å¦‚æœæœ‰å¤šä¸ªæ©ç ï¼Œéœ€è¦åˆ†åˆ«å¤„ç†

text1 = "æˆ‘å–œæ¬¢[MASK]ã€‚"
text2 = "ä»–æ˜¯ä¸€ä½[MASK]çš„ç§‘å­¦å®¶ã€‚"

result1 = unmasker(text1, top_k=1)
result2 = unmasker(text2, top_k=1)
```

### 3. å¥å­è¡¥å…¨

```python
def complete_sentence(incomplete_text, unmasker):
    """
    è‡ªåŠ¨è¡¥å…¨å¥å­
    """
    # åœ¨å¥å­æœ«å°¾æ·»åŠ æ©ç 
    text_with_mask = incomplete_text + "[MASK]"
    
    # é¢„æµ‹
    results = unmasker(text_with_mask, top_k=5)
    
    # è¿”å›è¡¥å…¨çš„å¥å­
    completions = []
    for result in results:
        completions.append({
            'text': result['sequence'],
            'word': result['token_str'],
            'score': result['score']
        })
    
    return completions

# ä½¿ç”¨
incomplete = "äººå·¥æ™ºèƒ½æ˜¯"
completions = complete_sentence(incomplete, unmasker)

for comp in completions:
    print(f"{comp['text']} ({comp['score']:.2%})")
```

### 4. æ–‡æœ¬çº é”™

```python
def correct_text(text_with_error, correct_word, unmasker):
    """
    å°†å¯èƒ½é”™è¯¯çš„è¯æ›¿æ¢ä¸º [MASK]ï¼Œè®©æ¨¡å‹é¢„æµ‹æ­£ç¡®çš„è¯
    """
    # æ›¿æ¢é”™è¯¯è¯ä¸ºæ©ç 
    text_masked = text_with_error.replace(correct_word, "[MASK]")
    
    # é¢„æµ‹
    results = unmasker(text_masked, top_k=5)
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ­£ç¡®çš„è¯
    for result in results:
        if result['token_str'] == correct_word:
            return {
                'is_correct': True,
                'confidence': result['score'],
                'alternatives': results
            }
    
    return {
        'is_correct': False,
        'suggestions': results
    }
```

## ğŸ¯ åº”ç”¨ç¤ºä¾‹

### 1. æ™ºèƒ½è¾“å…¥æ³•

```python
class SmartInput:
    def __init__(self, model_name="bert-base-chinese"):
        self.unmasker = pipeline("fill-mask", model=model_name)
    
    def suggest_next_word(self, text, top_k=5):
        """
        é¢„æµ‹ä¸‹ä¸€ä¸ªè¯
        """
        text_with_mask = text + "[MASK]"
        results = self.unmasker(text_with_mask, top_k=top_k)
        
        suggestions = []
        for result in results:
            word = result['token_str']
            score = result['score']
            suggestions.append((word, score))
        
        return suggestions
    
    def auto_complete(self, partial_word, context=""):
        """
        è‡ªåŠ¨è¡¥å…¨
        """
        text = context + partial_word + "[MASK]"
        results = self.unmasker(text, top_k=10)
        
        # è¿‡æ»¤å‡ºä»¥ partial_word å¼€å¤´çš„è¯
        completions = []
        for result in results:
            word = result['token_str']
            if word.startswith(partial_word):
                completions.append(word)
        
        return completions

# ä½¿ç”¨
smart_input = SmartInput()

# é¢„æµ‹ä¸‹ä¸€ä¸ªè¯
suggestions = smart_input.suggest_next_word("ä»Šå¤©å¤©æ°”")
print("å»ºè®®è¯:", suggestions)

# è‡ªåŠ¨è¡¥å…¨
completions = smart_input.auto_complete("å¤©", "ä»Šå¤©")
print("è¡¥å…¨:", completions)
```

### 2. æ‹¼å†™æ£€æŸ¥

```python
class SpellChecker:
    def __init__(self, model_name="bert-base-chinese"):
        self.unmasker = pipeline("fill-mask", model=model_name)
    
    def check_word(self, sentence, word_position):
        """
        æ£€æŸ¥æŒ‡å®šä½ç½®çš„è¯æ˜¯å¦æ­£ç¡®
        """
        words = list(sentence)
        original_word = words[word_position]
        
        # æ›¿æ¢ä¸ºæ©ç 
        words[word_position] = "[MASK]"
        masked_sentence = "".join(words)
        
        # é¢„æµ‹
        results = self.unmasker(masked_sentence, top_k=10)
        
        # æ£€æŸ¥åŸè¯æ˜¯å¦åœ¨é¢„æµ‹ä¸­
        for i, result in enumerate(results):
            if result['token_str'] == original_word:
                return {
                    'is_correct': True,
                    'confidence': result['score'],
                    'rank': i + 1
                }
        
        # å¦‚æœä¸åœ¨é¢„æµ‹ä¸­ï¼Œè¿”å›å»ºè®®
        return {
            'is_correct': False,
            'suggestions': [r['token_str'] for r in results[:5]]
        }

# ä½¿ç”¨
checker = SpellChecker()
result = checker.check_word("ä»Šå¤©å¤©æ±½çœŸå¥½", 3)  # æ£€æŸ¥"æ±½"å­—
print(result)
```

### 3. å¡«ç©ºç»ƒä¹ ç”Ÿæˆ

```python
class ExerciseGenerator:
    def __init__(self, model_name="bert-base-chinese"):
        self.unmasker = pipeline("fill-mask", model=model_name)
    
    def generate_exercise(self, sentence, num_blanks=1):
        """
        ç”Ÿæˆå¡«ç©ºç»ƒä¹ 
        """
        import random
        
        words = list(sentence)
        
        # éšæœºé€‰æ‹©è¦æ©ç çš„ä½ç½®
        positions = random.sample(range(len(words)), num_blanks)
        
        # ä¿å­˜ç­”æ¡ˆ
        answers = []
        for pos in positions:
            answers.append(words[pos])
            words[pos] = "___"
        
        exercise = "".join(words)
        
        return {
            'exercise': exercise,
            'answers': answers,
            'positions': positions
        }
    
    def check_answer(self, exercise, user_answer, position):
        """
        æ£€æŸ¥ç­”æ¡ˆ
        """
        # å°†ç©ºæ ¼æ›¿æ¢ä¸ºæ©ç 
        text = exercise.replace("___", "[MASK]", 1)
        
        # é¢„æµ‹
        results = self.unmasker(text, top_k=10)
        
        # æ£€æŸ¥ç”¨æˆ·ç­”æ¡ˆ
        for result in results:
            if result['token_str'] == user_answer:
                return {
                    'correct': True,
                    'confidence': result['score']
                }
        
        return {
            'correct': False,
            'suggestions': [r['token_str'] for r in results[:3]]
        }

# ä½¿ç”¨
generator = ExerciseGenerator()

# ç”Ÿæˆç»ƒä¹ 
exercise = generator.generate_exercise("ä»Šå¤©å¤©æ°”çœŸå¥½", num_blanks=1)
print(f"ç»ƒä¹ : {exercise['exercise']}")
print(f"ç­”æ¡ˆ: {exercise['answers']}")

# æ£€æŸ¥ç­”æ¡ˆ
result = generator.check_answer(exercise['exercise'], "å¥½", 0)
print(result)
```

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

ä¸åŒæ¨¡å‹åœ¨ç›¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼š

```python
models = [
    "bert-base-chinese",
    "hfl/chinese-roberta-wwm-ext",
    "hfl/chinese-bert-wwm-ext"
]

test_sentence = "æˆ‘å–œæ¬¢[MASK]ç¼–ç¨‹ã€‚"

for model_name in models:
    print(f"\næ¨¡å‹: {model_name}")
    unmasker = pipeline("fill-mask", model=model_name)
    results = unmasker(test_sentence, top_k=3)
    
    for i, result in enumerate(results, 1):
        print(f"  {i}. {result['token_str']} ({result['score']:.2%})")
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ©ç æ ‡è®°**: ä¸åŒæ¨¡å‹ä½¿ç”¨ä¸åŒçš„æ©ç æ ‡è®°ï¼ˆ[MASK] æˆ– <mask>ï¼‰
2. **å•ä¸ªæ©ç **: ä¸€æ¬¡åªèƒ½å¡«å……ä¸€ä¸ªæ©ç è¯
3. **ä¸Šä¸‹æ–‡**: æä¾›è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ä¿¡æ¯å¯ä»¥æé«˜é¢„æµ‹å‡†ç¡®æ€§
4. **æ¨¡å‹é€‰æ‹©**: é’ˆå¯¹ç‰¹å®šé¢†åŸŸå¯èƒ½éœ€è¦å¾®è°ƒæ¨¡å‹
5. **è®¡ç®—èµ„æº**: å¤§æ¨¡å‹éœ€è¦æ›´å¤šå†…å­˜å’Œè®¡ç®—æ—¶é—´

## ğŸ”— ç›¸å…³èµ„æº

- [BERT è®ºæ–‡](https://arxiv.org/abs/1810.04805)
- [RoBERTa è®ºæ–‡](https://arxiv.org/abs/1907.11692)
- [Hugging Face Fill-Mask æ–‡æ¡£](https://huggingface.co/tasks/fill-mask)
- [ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹](https://github.com/ymcui/Chinese-BERT-wwm)
