# 📁 模型保存位置说明

## 🎯 设计原则

所有训练生成的模型都保存在**各自的任务子文件夹**中，不会污染主目录。

---

## 📂 问答系统模型保存位置

### 简单版模型

**保存路径**：
```
实战训练/文本任务/问答系统/中文问答模型/
```

**包含文件**：
```
中文问答模型/
├── config.json              # 模型配置
├── model.safetensors        # 模型权重
├── tokenizer_config.json    # 分词器配置
├── vocab.txt                # 词汇表
└── special_tokens_map.json  # 特殊标记映射
```

**训练命令**：
```bash
python 简单训练示例.py
# 或
开始训练.bat
```

---

### 高级版模型

**保存路径**：
```
实战训练/文本任务/问答系统/中文问答模型_高级版/
```

**包含文件**：
```
中文问答模型_高级版/
├── config.json              # 模型配置
├── model.safetensors        # 模型权重
├── tokenizer_config.json    # 分词器配置
├── vocab.txt                # 词汇表
└── special_tokens_map.json  # 特殊标记映射
```

**训练命令**：
```bash
python 高级训练示例.py
# 或
开始高级训练.bat
```

---

## 🗂️ 训练过程文件

### 训练输出目录

**简单版**：
```
实战训练/文本任务/问答系统/qa_model_output/
├── checkpoint-xxx/          # 训练检查点
└── runs/                    # TensorBoard 日志
```

**高级版**：
```
实战训练/文本任务/问答系统/qa_model_output_advanced/
├── checkpoint-xxx/          # 训练检查点
└── runs/                    # TensorBoard 日志
```

这些是训练过程中的临时文件，训练完成后会自动保存最终模型到上述位置。

---

## 🔍 如何使用保存的模型

### 方法 1：使用 Pipeline（推荐）

```python
from transformers import pipeline

# 使用简单版模型
qa = pipeline("question-answering", model="./中文问答模型")

# 使用高级版模型
qa = pipeline("question-answering", model="./中文问答模型_高级版")

# 问答
result = qa(question="问题", context="上下文")
print(result['answer'])
```

### 方法 2：手动加载

```python
from transformers import AutoTokenizer, AutoModelForQuestionAnswering

# 加载模型
tokenizer = AutoTokenizer.from_pretrained("./中文问答模型")
model = AutoModelForQuestionAnswering.from_pretrained("./中文问答模型")

# 使用模型...
```

### 方法 3：使用绝对路径

```python
import os

# 获取模型绝对路径
model_path = os.path.join(
    r"D:\transformers训练\transformers-main",
    "实战训练", "文本任务", "问答系统", "中文问答模型"
)

qa = pipeline("question-answering", model=model_path)
```

---

## 📊 模型大小

| 模型 | 大小 | 说明 |
|------|------|------|
| 简单版 | ~400 MB | bert-base-chinese |
| 高级版 | ~400 MB | hfl/chinese-roberta-wwm-ext |

---

## 🗑️ 清理模型文件

如果需要重新训练或清理空间：

### Windows 命令

```cmd
# 删除简单版模型
rmdir /s /q 中文问答模型

# 删除高级版模型
rmdir /s /q 中文问答模型_高级版

# 删除训练输出
rmdir /s /q qa_model_output
rmdir /s /q qa_model_output_advanced
```

### 或手动删除

直接在文件管理器中删除对应文件夹即可。

---

## 📦 模型备份

如果想备份训练好的模型：

### 方法 1：复制整个文件夹

```cmd
# 备份到其他位置
xcopy /E /I 中文问答模型 D:\模型备份\问答模型_简单版
xcopy /E /I 中文问答模型_高级版 D:\模型备份\问答模型_高级版
```

### 方法 2：压缩打包

右键点击文件夹 → 发送到 → 压缩文件

---

## 🚀 部署模型

### 本地部署

模型已经在本地，可以直接使用相对路径或绝对路径加载。

### 上传到 Hugging Face Hub

```python
from transformers import AutoTokenizer, AutoModelForQuestionAnswering

# 加载模型
tokenizer = AutoTokenizer.from_pretrained("./中文问答模型")
model = AutoModelForQuestionAnswering.from_pretrained("./中文问答模型")

# 上传到 Hub
model.push_to_hub("your-username/chinese-qa-model")
tokenizer.push_to_hub("your-username/chinese-qa-model")
```

### 部署为 API

参考 `实战训练/情感分析/` 中的 Flask API 示例。

---

## 💡 注意事项

1. ✅ **模型保存在子文件夹**：不会污染主目录
2. ✅ **使用相对路径**：脚本在哪里运行，模型就保存在哪里
3. ✅ **自动创建目录**：不需要手动创建文件夹
4. ✅ **覆盖旧模型**：重新训练会覆盖同名模型
5. ⚠️ **不要提交到 Git**：模型文件已添加到 `.gitignore`

---

## 📝 其他任务的模型保存

所有训练任务都遵循相同的原则：

```
实战训练/
├── 文本任务/
│   ├── 问答系统/
│   │   └── 中文问答模型/          ← 问答模型
│   ├── 文本分类/
│   │   └── 分类模型/              ← 分类模型
│   └── ...
├── 图像任务/
│   ├── 图像分类/
│   │   └── 图像分类模型/          ← 图像分类模型
│   └── ...
└── 情感分析/
    └── my_sentiment_model/        ← 情感分析模型
```

每个任务的模型都保存在各自的文件夹中，互不干扰。

---

**模型保存位置清晰明确，便于管理和使用！** ✅
