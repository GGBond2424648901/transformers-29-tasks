#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥ RoBERTa æ¨¡å‹æ˜¯å¦å¯ä»¥åŠ è½½
"""

import os
os.environ['HF_HOME'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'
os.environ['TRANSFORMERS_CACHE'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'

print("=" * 70)
print("ğŸ” æ£€æŸ¥ RoBERTa æ¨¡å‹")
print("=" * 70)

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
model_path = r"D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„\hub\models--hfl--chinese-roberta-wwm-ext"
print(f"\nğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")

import os
if os.path.exists(model_path):
    print("âœ… æ¨¡å‹æ–‡ä»¶å¤¹å­˜åœ¨")
    
    # åˆ—å‡ºæ–‡ä»¶
    for root, dirs, files in os.walk(model_path):
        for file in files:
            if file.endswith(('.bin', '.safetensors', '.json', '.txt')):
                full_path = os.path.join(root, file)
                size = os.path.getsize(full_path)
                print(f"   {file}: {size / 1024 / 1024:.1f} MB")
else:
    print("âŒ æ¨¡å‹æ–‡ä»¶å¤¹ä¸å­˜åœ¨")

# å°è¯•åŠ è½½
print("\n" + "=" * 70)
print("ğŸ”„ å°è¯•åŠ è½½æ¨¡å‹")
print("=" * 70)

from transformers import AutoTokenizer, AutoModelForQuestionAnswering
import torch

print(f"\nğŸ“Š PyTorch ç‰ˆæœ¬: {torch.__version__}")
print(f"ğŸ“Š CUDA å¯ç”¨: {torch.cuda.is_available()}")

model_name = "hfl/chinese-roberta-wwm-ext"

# æ–¹æ³• 1: é»˜è®¤åŠ è½½
print(f"\næ–¹æ³• 1: é»˜è®¤åŠ è½½")
try:
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForQuestionAnswering.from_pretrained(model_name)
    print("âœ… æˆåŠŸï¼å¯ä»¥ä½¿ç”¨ RoBERTa")
    print(f"   æ¨¡å‹ç±»å‹: {type(model).__name__}")
except Exception as e:
    print(f"âŒ å¤±è´¥: {str(e)[:200]}")

# æ–¹æ³• 2: ä½¿ç”¨ use_safetensors=False
print(f"\næ–¹æ³• 2: å¼ºåˆ¶ä½¿ç”¨ pytorch_model.bin")
try:
    model = AutoModelForQuestionAnswering.from_pretrained(
        model_name,
        use_safetensors=False
    )
    print("âœ… æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ å¤±è´¥: {str(e)[:200]}")

# æ–¹æ³• 3: ä½¿ç”¨ trust_remote_code
print(f"\næ–¹æ³• 3: ä½¿ç”¨ trust_remote_code")
try:
    model = AutoModelForQuestionAnswering.from_pretrained(
        model_name,
        trust_remote_code=True
    )
    print("âœ… æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ å¤±è´¥: {str(e)[:200]}")

print("\n" + "=" * 70)
print("ğŸ“ ç»“è®º")
print("=" * 70)

print("""
å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¯´æ˜éœ€è¦å‡çº§ PyTorchï¼š

å‡çº§å‘½ä»¤ï¼š
pip install --upgrade torch==2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

å‡çº§åé‡æ–°è¿è¡Œæ­¤è„šæœ¬æ£€æŸ¥ã€‚
""")
