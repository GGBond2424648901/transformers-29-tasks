#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen2.5 æ™ºèƒ½å®¢æœ Web æœåŠ¡
æä¾›ç½‘é¡µèŠå¤©ç•Œé¢
"""

import os
os.environ['HF_HOME'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'
os.environ['TRANSFORMERS_CACHE'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'

from flask import Flask, request, jsonify, render_template_string, send_file
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import time

app = Flask(__name__)

# å…¨å±€å˜é‡
model = None
tokenizer = None
model_info = {}

# ============================================================================
# åŠ è½½æ¨¡å‹
# ============================================================================

def load_model():
    """åŠ è½½ Qwen2.5 + LoRA æ¨¡å‹"""
    global model, tokenizer, model_info
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    print("=" * 70)
    print("ğŸ¤– åŠ è½½ Qwen2.5 å®¢æœæ¨¡å‹")
    print("=" * 70)
    
    base_model = "Qwen/Qwen2.5-1.5B-Instruct"
    lora_path = os.path.join(script_dir, "output/chatglm-customer-lora")
    
    try:
        # åŠ è½½ tokenizer
        print("\nğŸ“¥ åŠ è½½ tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(
            base_model,
            trust_remote_code=True
        )
        print("âœ… Tokenizer åŠ è½½æˆåŠŸ")
        
        # åŠ è½½åŸºç¡€æ¨¡å‹
        print("\nğŸ“¥ åŠ è½½åŸºç¡€æ¨¡å‹...")
        model = AutoModelForCausalLM.from_pretrained(
            base_model,
            trust_remote_code=True,
            device_map="auto",
            torch_dtype=torch.float16
        )
        print("âœ… åŸºç¡€æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # åŠ è½½ LoRA æƒé‡
        if os.path.exists(lora_path):
            print(f"\nğŸ“¥ åŠ è½½ LoRA æƒé‡: {lora_path}")
            model = PeftModel.from_pretrained(model, lora_path)
            model_info = {
                "name": "ChatGLM-6B å®¢æœç‰ˆï¼ˆLoRA å¾®è°ƒï¼‰",
                "type": "å¾®è°ƒæ¨¡å‹",
                "status": "å·²åŠ è½½"
            }
            print("âœ… LoRA æƒé‡åŠ è½½æˆåŠŸ")
        else:
            model_info = {
                "name": "ChatGLM-6Bï¼ˆåŸå§‹ï¼‰",
                "type": "åŸºç¡€æ¨¡å‹",
                "status": "å·²åŠ è½½ï¼ˆæœªå¾®è°ƒï¼‰"
            }
            print("âš ï¸  æœªæ‰¾åˆ° LoRA æƒé‡ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å‹")
        
        model = model.eval()
        
        device = "GPU" if torch.cuda.is_available() else "CPU"
        model_info["device"] = device
        
        print(f"\nâœ… æ¨¡å‹åŠ è½½å®Œæˆ")
        print(f"   è®¾å¤‡: {device}")
        return True
        
    except Exception as e:
        print(f"\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("\nğŸ’¡ æç¤ºï¼š")
        print("1. é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ ChatGLM-6Bï¼ˆçº¦ 12GBï¼‰")
        print("2. è¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸")
        print("3. æˆ–å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆ LoRA æƒé‡")
        return False

# ============================================================================
# HTML æ¨¡æ¿
# ============================================================================

HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ™ºèƒ½å®¢æœç³»ç»Ÿ - ChatGLM</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-image: url('/static/background');
            background-size: cover;
            background-position: center;
            background-attachment: fixed;
            background-repeat: no-repeat;
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
        }
        
        .header {
            text-align: center;
            color: white;
            margin-bottom: 30px;
        }
        
        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .model-info {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 15px;
            padding: 15px 20px;
            margin-bottom: 20px;
            box-shadow: 0 8px 32px rgba(0,0,0,0.1);
        }
        
        .chat-container {
            background: white;
            border-radius: 15px;
            box-shadow: 0 8px 32px rgba(0,0,0,0.1);
            height: 600px;
            display: flex;
            flex-direction: column;
        }
        
        .chat-messages {
            flex: 1;
            overflow-y: auto;
            padding: 20px;
        }
        
        .message {
            margin-bottom: 15px;
            display: flex;
            align-items: flex-start;
        }
        
        .message.user {
            justify-content: flex-end;
        }
        
        .message-content {
            max-width: 70%;
            padding: 12px 18px;
            border-radius: 18px;
            word-wrap: break-word;
            white-space: pre-wrap;
        }
        
        .message.user .message-content {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }
        
        .message.assistant .message-content {
            background: #f0f0f0;
            color: #333;
        }
        
        .chat-input-container {
            padding: 20px;
            border-top: 1px solid #e0e0e0;
        }
        
        .chat-input-wrapper {
            display: flex;
            gap: 10px;
        }
        
        #userInput {
            flex: 1;
            padding: 12px 18px;
            border: 2px solid #e0e0e0;
            border-radius: 25px;
            font-size: 16px;
            outline: none;
            transition: border-color 0.3s;
        }
        
        #userInput:focus {
            border-color: #667eea;
        }
        
        #sendBtn {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            padding: 12px 30px;
            border-radius: 25px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 600;
            transition: transform 0.2s;
        }
        
        #sendBtn:hover {
            transform: translateY(-2px);
        }
        
        #sendBtn:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }
        
        .loading {
            display: none;
            text-align: center;
            padding: 10px;
            color: #667eea;
        }
        
        .quick-questions {
            padding: 15px 20px;
            border-top: 1px solid #e0e0e0;
        }
        
        .quick-questions h4 {
            color: #667eea;
            margin-bottom: 10px;
        }
        
        .quick-btn {
            display: inline-block;
            margin: 5px;
            padding: 8px 15px;
            background: #f0f0f0;
            border: none;
            border-radius: 15px;
            cursor: pointer;
            font-size: 14px;
            transition: background 0.3s;
        }
        
        .quick-btn:hover {
            background: #e0e0e0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¤– æ™ºèƒ½å®¢æœç³»ç»Ÿ</h1>
            <p>åŸºäº ChatGLM-6B LoRA å¾®è°ƒ</p>
        </div>
        
        <div class="model-info">
            <strong>æ¨¡å‹:</strong> {{ model_info.name }} | 
            <strong>ç±»å‹:</strong> {{ model_info.type }} | 
            <strong>è®¾å¤‡:</strong> {{ model_info.device }} | 
            <strong>çŠ¶æ€:</strong> {{ model_info.status }}
        </div>
        
        <div class="chat-container">
            <div class="chat-messages" id="chatMessages">
                <div class="message assistant">
                    <div class="message-content">
                        æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½å®¢æœåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ
                    </div>
                </div>
            </div>
            
            <div class="loading" id="loading">
                æ­£åœ¨æ€è€ƒä¸­...
            </div>
            
            <div class="quick-questions">
                <h4>ğŸ’¡ å¿«é€Ÿæé—®</h4>
                <button class="quick-btn" onclick="sendQuickQuestion('å¦‚ä½•é€€è´§ï¼Ÿ')">å¦‚ä½•é€€è´§ï¼Ÿ</button>
                <button class="quick-btn" onclick="sendQuickQuestion('å‘è´§éœ€è¦å¤šä¹…ï¼Ÿ')">å‘è´§éœ€è¦å¤šä¹…ï¼Ÿ</button>
                <button class="quick-btn" onclick="sendQuickQuestion('æ”¯æŒå“ªäº›æ”¯ä»˜æ–¹å¼ï¼Ÿ')">æ”¯æŒå“ªäº›æ”¯ä»˜æ–¹å¼ï¼Ÿ</button>
                <button class="quick-btn" onclick="sendQuickQuestion('å¦‚ä½•è”ç³»å®¢æœï¼Ÿ')">å¦‚ä½•è”ç³»å®¢æœï¼Ÿ</button>
            </div>
            
            <div class="chat-input-container">
                <div class="chat-input-wrapper">
                    <input type="text" id="userInput" placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜..." onkeypress="handleKeyPress(event)">
                    <button id="sendBtn" onclick="sendMessage()">å‘é€</button>
                </div>
            </div>
        </div>
    </div>
    
    <script>
        function addMessage(content, isUser) {
            const messagesDiv = document.getElementById('chatMessages');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${isUser ? 'user' : 'assistant'}`;
            
            const contentDiv = document.createElement('div');
            contentDiv.className = 'message-content';
            contentDiv.textContent = content;
            
            messageDiv.appendChild(contentDiv);
            messagesDiv.appendChild(messageDiv);
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }
        
        async function sendMessage() {
            const input = document.getElementById('userInput');
            const sendBtn = document.getElementById('sendBtn');
            const loading = document.getElementById('loading');
            const question = input.value.trim();
            
            if (!question) return;
            
            // æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            addMessage(question, true);
            input.value = '';
            
            // ç¦ç”¨è¾“å…¥
            sendBtn.disabled = true;
            input.disabled = true;
            loading.style.display = 'block';
            
            try {
                const response = await fetch('/api/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ question: question })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    addMessage(data.response, false);
                } else {
                    addMessage('æŠ±æ­‰ï¼Œå‡ºç°äº†é”™è¯¯ï¼š' + data.error, false);
                }
            } catch (error) {
                addMessage('æŠ±æ­‰ï¼Œç½‘ç»œé”™è¯¯ï¼š' + error.message, false);
            } finally {
                sendBtn.disabled = false;
                input.disabled = false;
                loading.style.display = 'none';
                input.focus();
            }
        }
        
        function sendQuickQuestion(question) {
            document.getElementById('userInput').value = question;
            sendMessage();
        }
        
        function handleKeyPress(event) {
            if (event.key === 'Enter') {
                sendMessage();
            }
        }
    </script>
</body>
</html>
"""

# ============================================================================
# è·¯ç”±
# ============================================================================

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template_string(HTML_TEMPLATE, model_info=model_info)

@app.route('/static/background')
def background():
    """æä¾›èƒŒæ™¯å›¾ç‰‡"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    bg_path = os.path.join(script_dir, 'èƒŒæ™¯.png')
    return send_file(bg_path, mimetype='image/png')

@app.route('/api/chat', methods=['POST'])
def chat():
    """èŠå¤© API"""
    try:
        data = request.json
        question = data.get('question', '').strip()
        
        if not question:
            return jsonify({
                'success': False,
                'error': 'é—®é¢˜ä¸èƒ½ä¸ºç©º'
            })
        
        # æ„å»º Qwen2.5 æ ¼å¼çš„æç¤º
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ™ºèƒ½å®¢æœåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›å‡†ç¡®ã€å‹å¥½çš„å›ç­”ã€‚"},
            {"role": "user", "content": question}
        ]
        
        # ä½¿ç”¨ tokenizer çš„ apply_chat_template
        text = tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        # è°ƒç”¨æ¨¡å‹ç”Ÿæˆ
        start_time = time.time()
        inputs = tokenizer([text], return_tensors="pt").to(model.device)
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=512,
                temperature=0.7,
                top_p=0.8,
                do_sample=True
            )
        
        # è§£ç è¾“å‡º
        response = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)
        elapsed_time = time.time() - start_time
        
        return jsonify({
            'success': True,
            'response': response.strip(),
            'time': f"{elapsed_time:.2f}s"
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/info', methods=['GET'])
def info():
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    return jsonify(model_info)

# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

if __name__ == '__main__':
    print("\n" + "=" * 70)
    print("ğŸš€ å¯åŠ¨ Qwen2.5 æ™ºèƒ½å®¢æœç³»ç»Ÿ")
    print("=" * 70)
    
    # åŠ è½½æ¨¡å‹
    if not load_model():
        print("\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨æœåŠ¡")
        exit(1)
    
    print("\n" + "=" * 70)
    print("âœ… æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
    print("=" * 70)
    print("\nğŸ“± è®¿é—®åœ°å€:")
    print("   æœ¬åœ°: http://127.0.0.1:5000")
    print("   å±€åŸŸç½‘: http://0.0.0.0:5000")
    print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print("   1. åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ä¸Šè¿°åœ°å€")
    print("   2. è¾“å…¥é—®é¢˜è¿›è¡Œå¯¹è¯")
    print("   3. æˆ–ç‚¹å‡»å¿«é€Ÿæé—®æŒ‰é’®")
    print("\nâš ï¸  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    print("=" * 70 + "\n")
    
    # å¯åŠ¨æœåŠ¡
    app.run(host='0.0.0.0', port=5000, debug=False)
