#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘+æ–‡æœ¬ç†è§£ç¤ºä¾‹
å¤šæ¨¡æ€éŸ³é¢‘å†…å®¹ç†è§£
"""

import os
os.environ['HF_HOME'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'
os.environ['TRANSFORMERS_CACHE'] = r'D:\transformersè®­ç»ƒ\transformers-main\é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å¤„'

print("=" * 70)
print("ğŸµğŸ’¬ éŸ³é¢‘+æ–‡æœ¬ç†è§£ç¤ºä¾‹")
print("=" * 70)

print("""
âš ï¸  æ³¨æ„ï¼š
éŸ³é¢‘+æ–‡æœ¬ç†è§£é€šå¸¸éœ€è¦ç»„åˆå¤šä¸ªæ¨¡å‹ï¼š

æ–¹æ¡ˆ1ï¼šASR + æ–‡æœ¬ç†è§£
```python
from transformers import pipeline

# 1. è¯­éŸ³è½¬æ–‡æœ¬
asr = pipeline("automatic-speech-recognition")
text = asr("audio.mp3")["text"]

# 2. æ–‡æœ¬ç†è§£/åˆ†ç±»
classifier = pipeline("text-classification")
result = classifier(text)
```

æ–¹æ¡ˆ2ï¼šä½¿ç”¨ Qwen2-Audio (æ¨è)
```python
# ç«¯åˆ°ç«¯éŸ³é¢‘ç†è§£
# æ”¯æŒéŸ³é¢‘é—®ç­”ã€éŸ³é¢‘åˆ†ç±»ç­‰
model_name = "Qwen/Qwen2-Audio-7B"
```

åº”ç”¨åœºæ™¯ï¼š
- ğŸ™ï¸ ä¼šè®®çºªè¦ - è‡ªåŠ¨æ€»ç»“
- ğŸ“ å®¢æœåˆ†æ - æƒ…æ„Ÿè¯†åˆ«
- ğŸµ éŸ³ä¹ç†è§£ - é£æ ¼åˆ†ç±»
- ğŸ“» æ’­å®¢åˆ†æ - å†…å®¹æå–

åŠŸèƒ½ç¤ºä¾‹ï¼š

1. éŸ³é¢‘é—®ç­”
```python
# å¯¹éŸ³é¢‘å†…å®¹æé—®
question = "è¿™æ®µéŸ³é¢‘åœ¨è®¨è®ºä»€ä¹ˆï¼Ÿ"
answer = audio_qa(audio="meeting.mp3", question=question)
```

2. éŸ³é¢‘åˆ†ç±»
```python
# è¯†åˆ«éŸ³é¢‘ç±»å‹
result = audio_classifier("audio.mp3")
# è¾“å‡ºï¼š{"label": "music", "score": 0.95}
```

3. éŸ³é¢‘æ‘˜è¦
```python
# ç”ŸæˆéŸ³é¢‘å†…å®¹æ‘˜è¦
summary = audio_summarizer("podcast.mp3")
```

æ¨èå·¥å…·ï¼š
- Qwen2-Audio: å¤šæ¨¡æ€éŸ³é¢‘ç†è§£
- Whisper + GPT: ç»„åˆæ–¹æ¡ˆ
- SeamlessM4T: è¯­éŸ³ç¿»è¯‘
""")

print("\nâœ¨ ç¤ºä¾‹å®Œæˆï¼")
