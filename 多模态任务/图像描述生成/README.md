# 📸 图像描述生成系统

自动为图像生成文字描述的 AI 系统

## 📋 项目说明

本项目使用预训练的 BLIP 模型，可以自动为上传的图片生成准确的文字描述。

### 🎯 功能特点

- ✅ **智能识别**：使用 Salesforce BLIP 模型，准确识别图像内容
- ✅ **中文翻译**：自动将英文描述翻译成中文
- ✅ **双语显示**：同时显示中文翻译和英文原文
- ✅ **多种模式**：支持生成单个描述或多个候选描述
- ✅ **拖拽上传**：支持点击上传或拖拽图片
- ✅ **实时预览**：上传后立即预览图片
- ✅ **美观界面**：现代化的 Web 界面设计
- ✅ **自定义背景**：使用自定义背景图片

## 🚀 快速开始

### 方法 1：使用启动脚本（推荐）

双击运行 `启动Web服务.bat`

### 方法 2：命令行启动

```bash
D:\aaaalokda\envs\myenv\python.exe 图像描述Web服务.py
```

### 访问服务

启动后在浏览器中访问：http://127.0.0.1:5000

## 📖 使用说明

### 1. 上传图片

- **方式 A**：点击上传区域，选择图片文件
- **方式 B**：直接拖拽图片到上传区域

### 2. 生成描述

- **生成描述**：生成单个最佳描述
- **生成多个描述**：生成 3 个候选描述供选择

### 3. 查看结果

系统会显示 AI 生成的图像描述，可以：
- 查看不同的描述选项
- 更换图片继续测试

## 🎨 应用场景

### 1. ♿ 无障碍辅助
为视障人士提供图像内容描述，提升网页可访问性

### 2. 🔍 图片 SEO
自动生成图片的 alt 文本，提升搜索引擎优化效果

### 3. 📱 社交媒体
为社交媒体图片自动生成说明文字

### 4. 📚 内容管理
批量为图片库生成标注和描述

### 5. 🏪 电商平台
自动生成商品图片描述

## 🤖 技术细节

### 使用的模型

**1. Salesforce/blip-image-captioning-base**（图像描述）
- 基于 BLIP (Bootstrapping Language-Image Pre-training)
- 在大规模图像-文本数据集上预训练
- 支持多种图像类型的描述生成
- 生成英文描述

**2. Helsinki-NLP/opus-mt-en-zh**（英译中）
- 基于 MarianMT 翻译模型
- 专门用于英文到中文的翻译
- 自动将英文描述翻译成中文
- 保留英文原文供参考

### 生成参数

**单个描述模式**：
- 使用默认参数生成最佳描述

**多个描述模式**：
- `max_new_tokens=50`：最多生成 50 个词
- `num_beams=5`：使用 beam search 提高质量
- `num_return_sequences=3`：返回 3 个候选描述

## 📁 项目结构

```
图像描述生成/
├── 图像描述Web服务.py      # Web 服务主程序
├── 图像描述生成示例.py      # 命令行示例
├── 启动Web服务.bat         # 启动脚本
├── 背景.png               # 自定义背景图片
└── README.md             # 本文档
```

## 💡 使用技巧

### 1. 图片质量
- 使用清晰、光线充足的图片
- 避免过度模糊或曝光的图片
- 主体明确的图片效果更好

### 2. 描述选择
- 单个描述：快速获取最佳结果
- 多个描述：对比选择最合适的描述

### 3. 性能优化
- 首次运行会下载模型（约 1GB）
- 后续运行直接使用缓存的模型
- GPU 环境下生成速度更快

## 🔧 环境要求

- Python 3.8+
- transformers 4.37.0+
- torch 2.0+
- flask 3.0+
- Pillow

## 📊 模型信息

### 图像描述模型

| 属性 | 说明 |
|------|------|
| 模型名称 | Salesforce/blip-image-captioning-base |
| 模型大小 | ~990 MB |
| 任务类型 | Image-to-Text |
| 输出语言 | 英文 |
| 训练数据 | COCO、Visual Genome 等 |

### 翻译模型

| 属性 | 说明 |
|------|------|
| 模型名称 | Helsinki-NLP/opus-mt-en-zh |
| 模型大小 | ~300 MB |
| 任务类型 | Translation (EN→ZH) |
| 翻译方向 | 英文 → 中文 |
| 训练数据 | OPUS 多语言语料库 |

## 🎓 进阶使用

### 其他推荐模型

如果需要更详细的描述，可以尝试：

```python
# 更大的 BLIP2 模型
captioner = pipeline("image-to-text", model="Salesforce/blip2-opt-2.7b")

# 轻量级模型
captioner = pipeline("image-to-text", model="nlpconnect/vit-gpt2-image-captioning")
```

### 自定义生成参数

```python
# 生成更长的描述
result = captioner(image, max_new_tokens=100)

# 使用更大的 beam size
result = captioner(image, num_beams=10)
```

## ❓ 常见问题

### Q1: 首次运行很慢？
A: 首次运行需要下载模型（约 1GB），请耐心等待。后续运行会使用缓存。

### Q2: 描述不准确？
A: 尝试：
- 使用更清晰的图片
- 生成多个描述进行对比
- 使用更大的模型（如 blip2-opt-2.7b）

### Q3: 支持中文描述吗？
A: BLIP 模型主要生成英文描述。如需中文，可以：
- 使用翻译 API 转换
- 使用支持中文的多模态模型

### Q4: 可以批量处理吗？
A: 当前版本是单张处理。如需批量处理，可以修改代码添加批处理功能。

## 📝 更新日志

### v1.0.0 (2026-01-31)
- ✅ 初始版本发布
- ✅ 支持图片上传和描述生成
- ✅ 提供 Web 界面
- ✅ 支持单个/多个描述生成
- ✅ 自定义背景图片

## 📄 许可证

本项目仅供学习和研究使用。

## 🙏 致谢

- Hugging Face Transformers
- Salesforce BLIP 模型
- Flask Web 框架
