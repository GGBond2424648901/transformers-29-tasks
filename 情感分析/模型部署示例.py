#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†è®­ç»ƒå¥½çš„æ¨¡å‹éƒ¨ç½²ä¸º Web API æœåŠ¡
éœ€è¦å®‰è£…: pip install flask
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline
import torch
import torch.nn.functional as F

# åˆ›å»º Flask åº”ç”¨
app = Flask(__name__)
# å¯ç”¨ CORSï¼ˆå…è®¸è·¨åŸŸè¯·æ±‚ï¼‰
CORS(app)

# å…¨å±€å˜é‡å­˜å‚¨æ¨¡å‹
model = None
tokenizer = None
classifier = None

def load_model():
    """åŠ è½½æ¨¡å‹"""
    global model, tokenizer, classifier
    
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    import os
    script_dir = os.path.dirname(os.path.abspath(__file__))
    model_path = os.path.join(script_dir, "my_sentiment_model")
    
    print(f"æ¨¡å‹è·¯å¾„: {model_path}")
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶å¤¹")
        print(f"   æœŸæœ›ä½ç½®: {model_path}")
        print(f"   å½“å‰ç›®å½•: {os.getcwd()}")
        print(f"\nğŸ’¡ è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•è¿è¡Œè„šæœ¬ï¼Œæˆ–å…ˆè®­ç»ƒæ¨¡å‹")
        exit(1)
    
    # æ–¹æ³•1: ä½¿ç”¨ pipelineï¼ˆç®€å•ï¼‰
    classifier = pipeline("text-classification", model=model_path)
    
    # æ–¹æ³•2: æ‰‹åŠ¨åŠ è½½ï¼ˆæ›´çµæ´»ï¼‰
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    
    print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸï¼")

@app.route('/')
def home():
    """é¦–é¡µ"""
    return """
    <h1>æƒ…æ„Ÿåˆ†æ API</h1>
    <p>ä½¿ç”¨æ–¹æ³•ï¼š</p>
    <ul>
        <li>POST /predict - å•ä¸ªæ–‡æœ¬é¢„æµ‹</li>
        <li>POST /batch_predict - æ‰¹é‡æ–‡æœ¬é¢„æµ‹</li>
        <li>GET /health - å¥åº·æ£€æŸ¥</li>
    </ul>
    <p>ç¤ºä¾‹è¯·æ±‚ï¼š</p>
    <pre>
    curl -X POST http://localhost:5000/predict \\
         -H "Content-Type: application/json" \\
         -d '{"text": "è¿™ä¸ªäº§å“å¾ˆå¥½"}'
    </pre>
    """

@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'ok',
        'model_loaded': model is not None
    })

@app.route('/predict', methods=['POST'])
def predict():
    """å•ä¸ªæ–‡æœ¬é¢„æµ‹"""
    try:
        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        
        if 'text' not in data:
            return jsonify({'error': 'ç¼ºå°‘ text å‚æ•°'}), 400
        
        text = data['text']
        
        # æ–¹æ³•1: ä½¿ç”¨ pipeline
        if data.get('use_pipeline', True):
            result = classifier(text)[0]
            return jsonify({
                'text': text,
                'label': result['label'],
                'score': float(result['score']),
                'sentiment': 'æ­£é¢' if result['label'] == 'LABEL_1' else 'è´Ÿé¢'
            })
        
        # æ–¹æ³•2: æ‰‹åŠ¨é¢„æµ‹ï¼ˆè¿”å›æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼‰
        inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
        
        with torch.no_grad():
            outputs = model(**inputs)
        
        probs = F.softmax(outputs.logits, dim=-1)
        negative_prob = probs[0][0].item()
        positive_prob = probs[0][1].item()
        
        return jsonify({
            'text': text,
            'sentiment': 'æ­£é¢' if positive_prob > negative_prob else 'è´Ÿé¢',
            'confidence': max(positive_prob, negative_prob),
            'probabilities': {
                'negative': negative_prob,
                'positive': positive_prob
            }
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/batch_predict', methods=['POST'])
def batch_predict():
    """æ‰¹é‡æ–‡æœ¬é¢„æµ‹"""
    try:
        data = request.get_json()
        
        if 'texts' not in data:
            return jsonify({'error': 'ç¼ºå°‘ texts å‚æ•°'}), 400
        
        texts = data['texts']
        
        if not isinstance(texts, list):
            return jsonify({'error': 'texts å¿…é¡»æ˜¯åˆ—è¡¨'}), 400
        
        # æ‰¹é‡é¢„æµ‹
        results = classifier(texts)
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for text, result in zip(texts, results):
            formatted_results.append({
                'text': text,
                'label': result['label'],
                'score': float(result['score']),
                'sentiment': 'æ­£é¢' if result['label'] == 'LABEL_1' else 'è´Ÿé¢'
            })
        
        return jsonify({
            'count': len(texts),
            'results': formatted_results
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    # å¯åŠ¨å‰åŠ è½½æ¨¡å‹
    load_model()
    
    # å¯åŠ¨ Flask æœåŠ¡
    print("\n" + "=" * 60)
    print("æƒ…æ„Ÿåˆ†æ API æœåŠ¡å·²å¯åŠ¨ï¼")
    print("è®¿é—®: http://localhost:5000")
    print("=" * 60 + "\n")
    
    app.run(host='0.0.0.0', port=5000, debug=False)
