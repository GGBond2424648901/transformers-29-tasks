# LoRA 微调项目清单

本文档列出所有使用 LoRA (Low-Rank Adaptation) 技术进行模型微调的项目。

---

## 📊 项目总览

| 序号 | 项目名称 | 任务类型 | 基础模型 | 模型压缩率 | 状态 |
|------|---------|---------|---------|-----------|------|
| 1 | 图像分类 | 图像任务 | ViT-Base | 99.3% | ✅ |
| 2 | 目标检测 | 图像任务 | DETR-ResNet-50 | 99.6% | ✅ |
| 3 | 姿态估计 | 图像任务 | ViT-Base | 99.4% | ✅ |
| 4 | ChatGLM智能客服 | 文本生成 | Qwen2.5-1.5B | - | ✅ |

**总计**: 4 个 LoRA 项目

---

## 🖼️ 图像任务 (3个)

### 1. 图像分类 LoRA
- **路径**: `实战训练/图像任务/图像分类/`
- **脚本**: `图像分类训练_LoRA.py`
- **基础模型**: google/vit-base-patch16-224
- **任务**: 5类图像分类（猫、狗、鸟、鱼、马）
- **模型大小**: 2.27 MB（原 330 MB）
- **压缩率**: 99.3%
- **性能**: 准确率 100%，F1分数 1.0000
- **训练时间**: ~30秒

### 2. 目标检测 LoRA
- **路径**: `实战训练/图像任务/目标检测/`
- **脚本**: `目标检测训练_LoRA.py`
- **基础模型**: facebook/detr-resnet-50
- **任务**: 检测圆形、方形、三角形
- **模型大小**: 0.59 MB（原 160 MB）
- **压缩率**: 99.6%
- **性能**: 训练损失从 9.18 降至 2.87
- **训练时间**: ~84秒

### 3. 姿态估计 LoRA
- **路径**: `实战训练/图像任务/姿态估计/`
- **脚本**: `姿态估计训练_LoRA.py`
- **基础模型**: google/vit-base-patch16-224
- **任务**: 5个关键点检测（头部、左手、右手、左脚、右脚）
- **模型大小**: ~2 MB LoRA权重（原 330 MB）
- **压缩率**: 99.4%
- **性能**: 像素误差 9.68，MAE 0.0432
- **训练时间**: ~35秒

---

## 📝 文本任务 (1个)

### 4. ChatGLM 智能客服微调
- **路径**: `实战训练/文本任务/文本生成/ChatGLM智能客服微调/`
- **脚本**: `chatglm_lora_finetune.py`
- **基础模型**: Qwen2.5-1.5B-Instruct
- **任务**: 智能客服对话生成
- **LoRA配置**: r=8, alpha=32
- **训练数据**: 1000条客服对话
- **应用**: Web服务 `customer_service_web.py`

---

## 🎯 LoRA 核心优势

### 模型压缩
- **平均压缩率**: 99.4%
- **最高压缩率**: 99.6%（目标检测）
- **最小模型**: 0.59 MB（目标检测）

### 训练效率
- **快速训练**: 所有图像任务 < 2分钟
- **低资源消耗**: 可训练参数 < 1%
- **GPU加速**: 自动检测并使用

### 性能表现
- **图像分类**: 准确率 100%
- **姿态估计**: 像素误差仅 9.68
- **目标检测**: 稳定收敛

---

## 📁 文件组织

```
实战训练/
├── 图像任务/
│   ├── 图像分类/
│   │   ├── 图像分类训练_LoRA.py
│   │   ├── trained_model_lora/
│   │   └── training_results_lora/
│   ├── 目标检测/
│   │   ├── 目标检测训练_LoRA.py
│   │   ├── trained_model_lora/
│   │   └── training_results_lora/
│   └── 姿态估计/
│       ├── 姿态估计训练_LoRA.py
│       ├── trained_model_lora/
│       └── training_results_lora/
└── 文本任务/
    └── 文本生成/
        └── ChatGLM智能客服微调/
            ├── chatglm_lora_finetune.py
            └── output/chatglm-customer-lora/
```

---

## 🔧 技术栈

- **LoRA库**: PEFT 0.4.0
- **深度学习框架**: PyTorch
- **Transformers**: Hugging Face Transformers
- **GPU**: NVIDIA RTX 3070 Laptop
- **Python**: 3.11.11

---

## 📚 相关文档

- `LoRA微调与模型优化完整指南.md` - LoRA技术详解
- `图像任务/LoRA训练总结.md` - 图像任务LoRA总结
- `图像任务/训练方式对比.md` - 传统训练 vs LoRA对比
- `文本任务/文本生成/ChatGLM智能客服微调/README.md` - ChatGLM项目说明

---

## ✅ 项目状态

- ✅ 所有 LoRA 训练脚本已创建并验证
- ✅ 模型压缩率达到 99%+
- ✅ 性能指标完整记录
- ✅ 可视化图表生成
- ✅ Web服务部署完成

---

**最后更新**: 2026年2月6日
